{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Notebook\n",
    "This notebook prepares a flat dataset of GPS tracking points for further analysis.\n",
    "* Data is loaded from .gpx files to a Spark SQL `DataFrame` using the custom `StravaLoader` class\n",
    "* Nested columns are flattened \n",
    "* Additional attributes such as speed and accumulated distance are calculated\n",
    "* Tracking points where the athlete is at rest are filtered out to better calculate pause times\n",
    "\n",
    "## Input parameters\n",
    "- `dataset` - The name of the dataset to load. Use \"strava-activities\" or \"strava-activities-subset\"\n",
    "- `pause_threshold_minutes` - The minimum gap in minutes between two *activity_blocks*. If the time gap between to consecutive tracking points is greater than this limit the two points belong to different blocks\n",
    "- `rest_speed_threshold_kmh[acticity_type]` - The upper limit for when to consider the athlete to be *at rest* for each `activity_type`. If the speed is lower than this limit the athlete is at rest and the tracking point will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = 'strava-activities-subset'\n",
    "pause_threshold_minutes = 10\n",
    "rest_speed_threshold_kmh = {\n",
    "    'Ride': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script\n",
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import coalesce, concat, lag, lit, lower, sum, unix_timestamp, max, min, \\\n",
    "                                  sin, cos, atan, sqrt, atan2, toRadians, round\n",
    "import pandas as pd\n",
    "from classes import StravaLoader\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.core.pylabtools import figsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data with `StravaLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize Strava activity loader\n",
    "sl = StravaLoader('s3', dataset, sc=sc, hiveContext=sqlContext)\n",
    "\n",
    "# Load the dataset\n",
    "df = sl.get_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute time gap between consecutive points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Partitioning on <athlete> and <activity_type>\n",
    "window = Window.partitionBy('athlete', 'activity_type').orderBy('unix_time')\n",
    "\n",
    "# Timestamp in seconds\n",
    "df = df.withColumn( \n",
    "    'TIME_unix_time', \n",
    "    unix_timestamp(df['time'], \"yyyy-MM-dd'T'HH:mm:ss'Z'\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function for calulation of speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_speed(df):\n",
    "    \n",
    "    R = 6371000 # Earth radius\n",
    "\n",
    "    # Latitude and longditude in radians\n",
    "    df = df.withColumn(\n",
    "        'DIST_@latR',\n",
    "        toRadians(df['@lat'])\n",
    "    )\n",
    "    df = df.withColumn(\n",
    "        'DIST_@lonR',\n",
    "        toRadians(df['@lon'])\n",
    "    )\n",
    "    \n",
    "    # Latitude and longditude in previous tracking point\n",
    "    df = df.withColumn(\n",
    "        'DIST_@latR_prev',\n",
    "        lag('DIST_@latR', count=1).over(window)\n",
    "    )\n",
    "    df = df.withColumn(\n",
    "        'DIST_@lonR_prev',\n",
    "        lag('DIST_@lonR', count=1).over(window)\n",
    "    )\n",
    "    \n",
    "    # Difference in latitude and longditude since previous tracking point\n",
    "    df = df.withColumn(\n",
    "        'DIST_@latR_diff',\n",
    "        coalesce(df['DIST_@latR'] - df['DIST_@latR_prev'], lit(0))\n",
    "    )\n",
    "    df = df.withColumn(\n",
    "        'DIST_@lonR_diff',\n",
    "        coalesce(df['@lonR'] - df['@lonR_prev'], lit(0))\n",
    "    )\n",
    "\n",
    "    # Havesine distance calculation between two tracking points\n",
    "    df = df.withColumn(\n",
    "        'DIST_a',\n",
    "        sin(df['DIST_@latR_diff']/2) * sin(df['DIST_@latR_diff']/2)\n",
    "        + cos(df['DIST_@latR']) * cos(df['DIST_@latR_prev'])\n",
    "        * sin(df['DIST_@lonR_diff']/2) * sin(df['DIST_@lonR_diff']/2)\n",
    "    )\n",
    "    df = df.withColumn(\n",
    "        'DIST_c',\n",
    "        2 * atan2(sqrt(df['DIST_a']), sqrt(1 - df['DIST_a']))\n",
    "    )\n",
    "    \n",
    "    # Distance between consecutive points\n",
    "    df = df.withColumn(\n",
    "        'DIST_diff_meters',\n",
    "        coalesce(R * df['c'], lit(0))\n",
    "    )\n",
    "    \n",
    "    # Momentary speed in km/h\n",
    "    df = df.withColumn(\n",
    "        'SPEED_kmh',\n",
    "        coalesce(\n",
    "            3.6 * df['DIST_diff_meters'] / (df['TIME_unix_time'] - lag('TIME_unix_time', count=1).over(window)),\n",
    "            lit(0)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate speed, filter points at rest and recalculate speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = calculate_speed(df)\n",
    "df = df.filter((df['activity_type']=='Ride') & (df['SPEED_kmh']>rest_speed_threshold_kmh['Ride']))\n",
    "df = calculate_speed(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derive activity blocks by checking distance between consecutive tracking points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Time difference in seconds between tracking point and previous tracking point\n",
    "df = df.withColumn(\n",
    "    'TIME_unix_time_diff',\n",
    "    df['TIME_unix_time'] - lag('TIME_unix_time', count=1).over(window)\n",
    ")\n",
    "\n",
    "# Indicator (0,1) of whether time difference is greater than threshold (new activity block)\n",
    "df = df.withColumn(\n",
    "    'BLOCK_isnew',\n",
    "    coalesce(\n",
    "        (df['TIME_unix_time_diff'] >= pause_threshold_minutes * 60).cast('integer'),\n",
    "        lit(0)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Sequence number of activity block per athlete and activity \n",
    "df = df.withColumn(\n",
    "    'BLOCK_seqnum', \n",
    "    sum('BLOCK_isnew').over(window)\n",
    ")\n",
    "\n",
    "# Activity block id \"<athlete>_<activity_type>_<integer>\"\n",
    "df = df.withColumn(\n",
    "    'BLOCK_id',\n",
    "    concat(\n",
    "        df['athlete'],\n",
    "        lit('_'),\n",
    "        lower(df['activity_type']),\n",
    "        lit('_'),\n",
    "        df['BLOCK_seqnum'].cast('string')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute activity block specific metrics, like accumulated distance within each block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "window_block = Window.partitionBy('BLOCK_id').orderBy('TIME_unix_time')\n",
    "\n",
    "df = df.withColumn(\n",
    "    'DIST_BLOCK_km',\n",
    "    sum('DIST_diff_meters').over(window_block) / 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, flatten the `DataFrame` and remove redundant columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dff = df.select( \n",
    "    df['@lat'].alias('lat'), \n",
    "    df['@lon'].alias('lon'), \n",
    "    df['ele'].alias('ele'), \n",
    "    df['extensions.gpxtpx:TrackPointExtension.gpxtpx:atemp'].alias('atemp'), \n",
    "    df['extensions.gpxtpx:TrackPointExtension.gpxtpx:cad'].alias('cad'), \n",
    "    df['extensions.gpxtpx:TrackPointExtension.gpxtpx:hr'].alias('hr'), \n",
    "    df['time'].alias('time'), \n",
    "    df['TIME_unix_time'].alias('time_seconds'), # Block time?\n",
    "    df['athlete'].alias('athlete'), \n",
    "    df['activity_type'].alias('activity_type'),\n",
    "    df['BLOCK_id'].alias('block_id'),\n",
    "    df['SPEED_kmh'],\n",
    "    df['DIST_diff_meters'],\n",
    "    df['DIST_BLOCK_km']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save flat dataset in parquet file format for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dff.write.mode('overwrite').parquet('s3n://larsbk/parquet/%s/' % dataset) # sl.path -> sl.root_path, sl.dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
